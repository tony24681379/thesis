\chapter{Design and Implementation}
\label{chap:design}
\section{Docker}
In native Docker, It has two part, Docker Client and Docker Daemon. Docker Daemon has many components include server, engine, registry, graph, driver and runC. To  support dump checkpoint and restore request, some of these steps should be implemented.

\subsection{Docker Client}
We implement 3 Docker commands in Docker Client, including checkpoint, restore, migrate. In checkpoint command should have these configurations:
\begin{itemize}
	\item image directory - Dump checkpoint image directory.
	\item work directory - Dump checkpoint image log directory.
	\item leave running - After dumping checkpoint image, keeping running container or not.
	\item pre-dump - Pre-dump checkpoint memory image to minimize frozen time.
	\item pre image directory - Define which version image to compare.
	\item track memory - Track memory to pre image directory image to minimize disk space.
\end{itemize}
In restore command should have these configurations:
\begin{itemize}
	\item image directory - Checkpoint image directory to restore from.
	\item work directory - Directory for restore log.
	\item force - Fore restoring container from image directory whether container is running or not.
\end{itemize}
In migrate command, it focus on Docker Swarm Scheduler filter configurations. In run command, we can do this with the environment variable or the label. Therefore, we implement environment variable and the label configurations in migrate command.

\subsection{Docker Daemon}
In native Docker Daemon, it doesn't support checkpoint and restore command.
Fortunately, it is already implemented in runC, so we have to add a proxy between Docker Daemon and runC, which can handle Docker Client's checkpoint and restore requests.

\section{Docker Swarm configuration}
As Figure \ref{fig:Docker Swarm with remote storage server}, we prepare a remote storage server for saving Docker containers dump checkpoint images. It should have fault tolerant to avoid service shout down. For these reasons, We choose glusterFS to be our experiments remote storage server.                            

After setting up glusterFS, we mount it to every Docker nodes in the same folder. To avoid mount it as absolute path in every Docker nodes, we mount it to Docker root which we can change configuration in Docker Daemon.

\begin{figure}[h]
\begin{center}
\includegraphics[width=15cm]{figure/swarm_docker_remote.png}
\end{center}
\caption{Docker Swarm with remote storage server}
\label{fig:Docker Swarm with remote storage server}
\end{figure}

\section{Docker containers migration in Docker Swarm}
Docker Swarm creates containers through Swarm scheduler to dispatch Docker nodes. If we want to specific assign which node we want to create containers, we have to set filters like constraint, affinity or dependency.
To migrate containers in Docker Swarm, we must avoid the containers which we want to migrate that migrate to an other nodes, instead of the same node.
\begin{enumerate}[Step 1.]
	\item Check Docker Swarm cluster has at least two Swarm nodes.
    \item Parse Docker Client requests to analyse label and environment variables, and transform label and environment variables to Docker Swarm filters.
    \item Add constraint filter to make sure the container which we want to migrate does not migrate to the same node.
    \item Pre-dump the container checkpoint image which we want to migrate to decrease container frozen time.
    \item Dump the container checkpoint image by tracking memory from pre-dump checkpoint image.
    \item Create empty container on the Docker Swarm scheduler chooses node.
    \item Restore the container to the Docker Swarm scheduler chooses node.
    \item Delete the checkpoint images.
    \item If the container was migrated which had set checkpoint restore rescheduling policy, it will restart checkpoint restore rescheduling policy \ref{sec:checkpoint restore rescheduling policy}.
\end{enumerate}

\section{Docker Swarm checkpoint and restoration \\rescheduling policy}
\label{sec:checkpoint restore rescheduling policy}
In Docker Swarm, it has rescheduling policy. As we set the reschedule policy when we start a container, whenever Swarm nodes fail, Swarm Manager will restart the containers which on the fail nodes to another alive Swarm Nodes.

We improve this policy that we dump the checkpoint image for every containers which we want to keep the container checkpoint for every containers checkpoint ticker pounding. Whenever Swarm Nodes fail, Swarm Manager will restore the containers which Swarm Manager has dumped the checkpoint. Otherwise, the checkpoint tickers policy provides version of checkpoint image by tracking memory. It only dump different memory page checkpoint to new version checkpoint image.

In addition, it also support high availability that whenever Docker Swarm primary manager fails, the others Swarm Manager replica instances will lead a new primary manager. After replica leading a new primary manager, it will restart container checkpoint tickers.
%By experment, it can save at least XX% hard disk space

\subsection{Docker Swarm container checkpoint tickers}
\begin{enumerate}[Step 1.]
	\item Set checkpoint-time label and version-group label when we create the container.
    \item Swarm Manager analyzes checkpoint label when the container has created. If version-group label doesn't set, version-group will be set to 5.
    \item After the container starting, starting the container checkpoint ticker. Container checkpoint tickers are pounding when users want to checkpoint container repeatedly at regular intervals. Container checkpoint tickers will do these steps:
    \begin{enumerate}[Step a.]
    \item Swarm Manager sends pre-dump checkpoint request to Swarm Node's Docker Daemon when every Pre-dump version start.
    \item After pre-dumping the container, Swarm Manager sends dump new version checkpoint request to Swarm Node's Docker Daemon. Every new checkpoint images track memory to last checkpoint version image, just save memory difference in new checkpoint image. We save version-group(default 5) versions in the same directory(Figure \ref{fig:Containers checkpoint versions in remote storage server}).
    \item Send delete checkpoint request to Swarm Node's Docker Daemon to delete oldest Pre-dump version directory whenever container has more than two Pre-dump versions directory.
    \end{enumerate}
\end{enumerate}

\begin{algorithm}[h]
    \caption{Checkpoint ticker algorithm}
    \begin{algorithmic}[1]
        \State Set checkpoint-ticker time and version-group labels when create the container
        \State Swarm Manager annlyzes labels
        \label{code:checkpointTicker}
        \While {Container running $\&$ ticker time pounding}
            \If {version $\%$ version-group == 0 } 
                \State pre-dump checkpoint image
            \EndIf
            \State dump checkpoint image
            \If { version-group directory $>$ 3 } 
                \State delete oldest pre-dump checkpoint directory
            \EndIf
            \State version = version + 1
            \If {version $\%$ version-group == 0 } 
                \State pre-dump = pre-dump + 1
            \EndIf
        \EndWhile
    \end{algorithmic}
\end{algorithm}

\begin{figure}[h]
\begin{center}
\includegraphics[width=15cm]{figure/checkpoint_demo.png}
\end{center}
\caption{Containers checkpoint versions in remote storage server}
\label{fig:Containers checkpoint versions in remote storage server}
\end{figure}

\subsection{Docker Swarm restore rescheduling policy}
\begin{enumerate}[Step 1.]
    \item Set reschedule:restore label when we create the container.
    \item Swarm Manager analyzes restore label when the container start.
    \item Whenever Swarm Nodes fail, Swarm Manager will restore the containers which Swarm Manager has dumped the last checkpoint version to another Swarm nodes.
    \item To avoid dumping checkpoint version failing at the same time, if restoring last version failing, Swarm Manager will retry second last version checkpoint to restore. It will retry version-group(default 5) times.
    \item If Swarm Manager retries version-group all fail, it will create and start a new container as normal Docker Swarm rescheduling policy.
    
\begin{algorithm}[h]
    \caption{Restore rescheduling policy algorithm}
    \begin{algorithmic}[1]
        \State Set restore rescheduling policy labels create the container
        \State Swarm Manager anlyzes labels
        \\
        \If {Swarm Node fail}
        	\State \textsc{Restore container}
        \EndIf
        \\
        \label{code:Restore}
        \Procedure{Restore container}{}
			\ForAll{containers on the fail Swarm Node}
				\State Create a empty container on the Docker Swarm Node.
				\For {version downto version - version-group}
					\State Restore checkpoint[version] container
				\EndFor
				\State Delete the container checkpoint image
				\If{Restore the container fail}
					\State Restart the container on the Docker Swarm Node.
				\EndIf
			\EndFor
		\EndProcedure
	\end{algorithmic}
\end{algorithm}

\end{enumerate}

\subsection{High availability of Swarm Manager in Docker Swarm checkpoint and restoration rescheduling policy}
Whenever Docker Swarm primary manager fails, the others Swarm Manager replica instances will lead a new primary manager. After replica leading a new primary manager, it searching every Docker Node's containers which has checkpoint restore rescheduling policy's label. If the containers has checkpoint restore rescheduling policy's label, Docker Swarm new primary manager will restart container checkpoint tickers.