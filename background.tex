\chapter{Background}
\label{chap:background}
\section{Docker}
Docker is a open-source project container engine. It provides an additional layer of abstraction and automation of operating-system-level virtualization on Linux. Docker engine include Docker client and Docker daemon.
\subsection{Docker client}
Docker is typical Client/Server architecture application. Docker client uses Docker command to send and receive requests to Docker daemon. Also, Docker supports remote RESTful API to send and receive HTTP requests to Docker daemon, it has been implemented by more than 10 programming languages.
\subsection{Docker daemon}
Docker daemon is a daemon that runs as system service. It has two the most importance features: 
\begin{itemize}
    \item Receive and handle Docker client's requests.
    \item Manage containers.
\end{itemize}
When docker daemon is running, it will run a server that receives requests from Docker clients or remote RESTful API. After receives requests, server will pass requests by router to find handler to handle the requests.
\section{Docker Swarm}
Docker Swarm is native clustering for Docker. It gathers several docker engines together into  one virtual docker engine. Docker Swarm serves standard Docker API, so it can be connected by Dokku, Docker Machine, Docker Compose, Jenkins, DockerUI, Drone, etc. And it also support Docker client of course.
In Docker Swarm, It has two components, Include Swarm master and Swarm node. Swarm master is the manager which handles Docker client and RESTful API requests and manages multiple Docker nodes resources. Docker node is an agent which sends heartbeat to discovery server to ensure Docker daemon is alive in the cluster.
\subsection{Discovery services}
Docker Swarm provides multiple discovery services backends. They are used to discovery nodes in the cluster. There are:
\begin{itemize}
    \item Using a distributed key/value store, like Consul, Etcd and Zookeeper.
    \item A static file or list of nodes.
    \item Docker Hub as a hosted discovery service
\end{itemize}
Otherwise, It also supports any modules which satisfy discovery API interface.
\subsection{Scheduler}
Docker Swarm scheduler decides which nodes to use when creating and running a container. It has two steps. First, It follows user's filters to decide which nodes are conform. Second, It passes through strategies to select the best node in the cluster.
\subsubsection{Filter}
Filters are divided into two categories, node filters and container configuration filters. Node filters operate on characteristics of the Docker host or on the configuration of the Docker daemon. Container configuration filters operate on characteristics of containers, or on the availability of images on a host.
The node filters are:
\begin{itemize}
    \item constraint
    \item container slots
    \item health filter
\end{itemize}
The container configuration filters are:
\begin{itemize}
    \item affinity
    \item dependency
    \item port filter
\end{itemize}
\subsubsection{Strategies}
The Docker Swarm scheduler features multiple strategies for ranking nodes. Swarm currently supports these values:
\begin{itemize}
    \item spread
    \item binpack
    \item random
\end{itemize}
Spread and binpack strategies compute rank according to a nodeâ€™s available CPU, its RAM, and the number of containers it has. It selects a node at random. Under the spread strategy, Swarm optimizes for the node with the least number of containers. The binpack strategy causes Swarm to optimize for the node which is most packed. The random strategy uses no computation, chooses nodes at random regardless of their available CPU or RAM.
\subsection{High availability}
In Docker Swarm, Swarm manager responses the cluster and manages the resources of multiple Docker nodes at scale. If Swarm master dies, we have to create a new one and deal with the interruption of service.
The High availability feature allows Docker swarm has multiple Swarm manager instances. We can create a primary manager and multiple replica instances. If we send requests to replica instances, it will be automatically proxied to the primary manager. In addition, if the primary manager fails, the others replica instances will lead a new primary manager.
\section{CRIU}
CRIU stands for Checkpoint and Restore in User Space, creates a complete snapshot of the state of a process, including things like memory contents, file descriptors, and even open tcp connections. It can be used for suspending and resuming processes, or live migrating them from one machine to another.

\ref{chap:background} and cite test \cite{Knight:1986:AMF:319838.319854, Sohi:1995:MP:225830.224451, Hammond:1998:DSS:291069.291020}.